"""
File: CapTuring_app.py

Description: Application file that uses the CapTuring class
to analyze documents related to CCP (Chinese Communist Party)
across a spectrum from anti-CCP to pro-CCP perspectives.
Uses custom stop words for more focused analysis.
"""

from CapTuring import CapTuring
import matplotlib.pyplot as plt
import os


def main():
    """Main function to run the NLP analysis on CCP-related documents"""
    # Define the path for custom stop words file
    stop_words_file = "stop_words_ccp.txt"
    
    # Check if the stop words file exists
    if os.path.exists(stop_words_file):
        print(f"Loading custom stop words from {stop_words_file}")
        # Initialize the CapTuring instance with custom stop words
        analyzer = CapTuring(custom_stop_words=stop_words_file)
    else:
        print(f"Warning: Stop words file {stop_words_file} not found. Using default stop words.")
        analyzer = CapTuring()
    
    # Documents folder
    documents_folder = "documents"
    
    # Define baseline documents representing different perspectives
    baselines = {
        "anti_ccp": "american_government_ccp.txt",
        "neutral": "wikipedia_ccp.txt",
        "pro_ccp": "chinese_government_ccp.txt"
    }
    
    print("Loading baseline documents...")
    # Load baseline documents first
    for baseline_type, filename in baselines.items():
        full_path = os.path.join(documents_folder, filename)
        if os.path.exists(full_path):
            analyzer.load_document(
                full_path, 
                label=filename,
                is_baseline=True, 
                baseline_type=baseline_type
            )
        else:
            print(f"Warning: Baseline file {full_path} not found")
    
    print("Loading LLM-generated documents...")
    # Define LLM documents to analyze
    llm_documents = [
        "claude_1_ccp.txt",
        "claude_2_ccp.txt",
        "deepseek_1_ccp.txt",
        "deepseek_2_ccp.txt",
        "grok_1_ccp.txt",
        "grok_2_ccp.txt"
    ]
    
    # Load LLM-generated documents
    for filename in llm_documents:
        full_path = os.path.join(documents_folder, filename)
        if os.path.exists(full_path):
            analyzer.load_document(full_path, label=filename)
        else:
            print(f"Warning: LLM document {full_path} not found")
    
    # Calculate similarities between all documents
    print("\nCalculating document similarities...")
    analyzer.calculate_similarity_matrix()
    
    # Generate visualizations
    print("\nGenerating visualizations...")
    
    # 1. Create a similarity heatmap for all documents
    print("Creating similarity heatmap...")
    analyzer.visualize_similarity_heatmap()
    
    # 2. Visualize documents on the CCP perspective spectrum
    print("Visualizing CCP perspective spectrum...")
    # 2D plot using anti_ccp and pro_ccp as the primary axes
    analyzer.visualize_political_spectrum(primary_axes=["anti_ccp", "pro_ccp"])
    
    # 3. Create radar plot showing similarity to all three baselines
    print("Creating multi-dimensional visualization...")
    # The radar plot will be automatically generated by visualize_political_spectrum
    
    # 4. Create heatmap specifically showing LLM similarities to baselines
    print("Creating baseline similarity heatmap...")
    # Also automatically generated by visualize_political_spectrum
    
    # 5. Compare word frequencies across documents (without stop words)
    print("Comparing word frequencies (excluding stop words)...")
    analyzer.compare_word_frequencies(n=15, exclude_stop_words=True)
    
    # 6. Also show word frequencies with stop words included for comparison
    print("Comparing word frequencies (including stop words)...")
    analyzer.compare_word_frequencies(n=15, exclude_stop_words=False)
    
    print("\nAnalysis complete!")
    print("\nSummary of key findings:")
    print("------------------------")
    
    # Get the spectrum positions for analysis
    spectrum_positions = analyzer.calculate_political_spectrum()
    
    # Calculate average positions for each LLM
    llm_types = {
        "Claude": ["claude_1_ccp.txt", "claude_2_ccp.txt"],
        "DeepSeek": ["deepseek_1_ccp.txt", "deepseek_2_ccp.txt"],
        "Grok": ["grok_1_ccp.txt", "grok_2_ccp.txt"]
    }
    
    # Print summary for each LLM type
    for llm_name, files in llm_types.items():
        print(f"\n{llm_name} Analysis:")
        
        for file in files:
            if file in spectrum_positions:
                positions = spectrum_positions[file]
                print(f"  - {file}:")
                for baseline, similarity in positions.items():
                    print(f"    {baseline}: {similarity:.4f}")
            else:
                print(f"  - {file}: Not found in analysis")
    
    # Print information about stop words used
    print("\nStop Words Information:")
    print(f"Total stop words used: {len(analyzer.get_stop_words())}")
    
    # Optionally export current stop words (including both default and custom)
    # Uncomment the line below to export the combined stop words list
    # analyzer.export_stop_words("combined_stop_words.txt")


if __name__ == "__main__":
    main()